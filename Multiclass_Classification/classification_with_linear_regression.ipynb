{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9adfcebd-c5a8-4a1f-9fbe-12890712d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy, math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "56799b7b-531c-48c5-8816-5f1b9724fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "isolet = fetch_ucirepo(id=54) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = isolet.data.features\n",
    "y = isolet.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "07113026-f14c-4a05-8eed-b0351501cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataframes into numpy arrays (matrices with real entries)\n",
    "X_array = np.array(X).T\n",
    "Y_array = OneHotEncoder().fit_transform(y).toarray().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "ed1e9702-634f-4e13-abab-36ef39043212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data to have feature mean 0 with standard deviation of 1\n",
    "X_std = (X_array - X_array.mean(1,keepdims=True))/X_array.std(1,keepdims = True)\n",
    "Y_std = (Y_array - Y_array.mean(1,keepdims=True))/Y_array.std(1,keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "4d65cbc9-39da-41ad-bbf3-462dd45e1f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 7797)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "cb5a948c-9126-4597-b0ab-8b09936cb611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 7797)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "d7d737a3-4f7a-4948-a5f7-8043c37b132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = number of features, m = number of observations, k = number of classes\n",
    "n,m = X_array.shape\n",
    "k = Y_array.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27206a5a-2307-422e-8a57-59a070819e64",
   "metadata": {},
   "source": [
    "We'll look for an optimal transformation matrix $W$ such that $W^TX \\approx Y$ through a least squares approach:\n",
    "$$ \\min_{W \\in \\mathbb{R}^{n \\times k}} \\  \\{ f(W) \\coloneqq \\lVert W^TX - Y \\rVert_F^2 + \\lambda \\lVert W \\rVert_F^2 \\}, $$\n",
    "where \n",
    "- $X \\in \\mathbb{R}^{n \\times m}$ is a data matrix.\n",
    "- $Y \\in \\mathbb{R}^{k \\times m}$ is a label matrix (one-hot-encoded matrix).\n",
    "- $W \\in \\mathbb{R}^{n \\times k}$ is a transformation matrix.  \n",
    "- $\\lambda > 0$ is a regularization hyperparameter.\n",
    "- $\\lVert \\cdot \\rVert_F$ is the Frobenius norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "60854043-bf38-4e52-9b0c-20c01fd89bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split the datasets X and Y into \"training\" and \"testing\" with a 70/30 split.\n",
    "m_train = int(np.ceil(m*0.7))\n",
    "m_test = int(m - m_train)\n",
    "\n",
    "# Randomly select columns (observations) to be a part of the training set.  \n",
    "train_index = np.random.choice(X_array.shape[1], m_train, replace = False)\n",
    "test_index = list(set(range(m)) - set(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "ba9c28a1-ccf1-4ca8-8fb4-8bf22a5402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_std[:,train_index]; Y_train = Y_std[:,train_index]\n",
    "X_test = X_std[:,test_index]; Y_test = Y_array[:,test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3fe78-fce3-425c-a6e5-40e236ae9135",
   "metadata": {},
   "source": [
    "The problem $$\\min_{W \\in \\mathbb{R}^{n \\times k}} \\  \\{ f(W) \\coloneqq \\lVert W^TX - Y \\rVert_F^2 + \\lambda \\lVert W \\rVert_F^2 \\}$$ is unconstrained.  Therefore, we can solve for $W$ directly with basic calculus.  \n",
    "\n",
    "First, we'll re-write $f(W)$ in its equivalent form by noting that for any matrix $C$ we have $\\lVert C \\rVert_F^2 = \\text{trace}(C^TC)$, where $\\text{trace}$ is the trace operator:  \n",
    "\n",
    "$$ f(W) = \\lVert Y \\rVert_F^2 + \\text{trace}(W^TXX^TW) - 2\\text{trace}(W^TXY^T) + \\lambda \\text{trace}(W^TW)$$\n",
    "\n",
    "Next, we can set the partial derivative of $f(W)$ with respect to $W$ equal to $0$, and solve for $W$:\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial W} = 2XX^TW - 2XY^T + 2\\lambda W = 0 $$\n",
    "$$ \\iff (XX^T + \\lambda I_n)W = XY^T $$ \n",
    "$$ \\Rightarrow W = (XX^T + \\lambda I_n)^{-1}(XY^T) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "b2548a2c-d0d8-42c0-a49c-92d0fcdf3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving for an optimal W given the data matrix X, label matrix Y, and lambda_val.  \n",
    "lambda_val = 100\n",
    "In = np.eye(n)\n",
    "W = scipy.linalg.inv(X_train@X_train.T + lambda_val*In)@(X_train@Y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "cb923e0a-bb64-4f7a-b72e-b1367c7c7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating estimate matrix Y_est and creating its label equivalent Y_est_label\n",
    "Y_est = W.T@X_test\n",
    "Y_est_label = np.zeros((k,n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "9c5d0f18-7cf1-4479-9ac6-d3a8c67ee3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each obsevation, look at the index (class) which has the highest value and consider that its classifcation.  \n",
    "for i in range(n_test):\n",
    "    temp_list = list(Y_est[:,i])\n",
    "    max_index = temp_list.index(max(temp_list))\n",
    "    Y_est_label[max_index,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "0b064886-d0db-4029-b719-770dc727f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform one-hot-encoded matrices back to vectors with class labels (1,2,...,k).  \n",
    "test_labels = np.argmax(Y_test, axis = 0)\n",
    "est_labels = np.argmax(Y_est_label, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "a63a3e85-ce29-416a-9759-0687a2a948fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "agreement = (test_labels == est_labels)*1\n",
    "accuracy = (sum(agreement)/n_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "805c0174-0a89-4c01-8219-586aa0626508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.90294997862334\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pred_modeling-env]",
   "language": "python",
   "name": "conda-env-pred_modeling-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
